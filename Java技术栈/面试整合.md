# Redis篇

## 使用场景

- 缓存
  - 穿透、击穿、雪崩
  - 双写一致、持久化
  - 数据过期、淘汰策略
- 分布式锁
  - setnx、redisson
- 计数器 （incr）
- 保存token（string）
- 消息队列 （list）
- 延迟队列 （zset）

### 缓存

#### 缓存穿透

缓存穿透：查询一个**不存在**的数据，mysql查询不到数据也不会直接写入缓存，就会导致每次请求都查询数据库

##### 解决方案

###### 缓存空数据![image-20240803171856089](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408031718207.png)

###### 布隆过滤器

通过bitmap（位图）一个以bit为单位的数组，数组中每个单元只能存储二进制数0或1，默认都为0，根据预热数据的id计算3次哈希值，将数组中对应位置变为1，查询数据时，如果3个对应位置都为1，则判断存在该数据![image-20240803172115383](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408031721467.png)

------



#### 缓存击穿

缓存穿透：给某一个key设置了过期时间，当key过期的时候，恰好这时间点对这个key有大量的并发请求过来，这些并发请求可能会瞬间吧DB压垮

##### 解决方案

###### 互斥锁

当缓存失效时，不立即去load DB，而先使用如Redis的setnx去设置一个互斥锁，当操作成功返回时再进行load DB操作并设置缓存。互斥锁，防止大量请求都进入数据库操作。

- 强一致性
- 性能差

<img src="https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408031733182.png" alt="image-20240803173343122" style="zoom:67%;" />

###### 逻辑过期

将热点数据提前加入缓存中，且不设置过期时间，而是新增一个逻辑过期时间字段，可以返回旧数据（逻辑过期）

- 高可用
- 性能优



<img src="https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408031734975.png" alt="image-20240803173403905" style="zoom:67%;" />

------



#### 缓存雪崩

缓存雪崩：指在同一时间段大量的缓存key同时失效或者Redis服务宕机，导致大量请求到达数据库，带来巨大压力

##### 解决方案

- 给不同key的TTL添加随机值
- 利用Redis集群提高服务的可用性（哨兵模式，集群模式）
- 给缓存业务添加降级限流策略（nginx或spring cloud gateway）
- 业务多级缓存（Guava或Caffeine）

------



#### 双写一致性

redis作为缓存，与mysql数据库进行同步，根据业务背景要求选择

- 一致性要求高
- 允许延迟一致

##### 为什么不采用延时双删？

**延时双删：**先删缓存，再操作数据库，延时，再删除缓存

**删除两次缓存**是为了降低脏数据的出现

**延时删除**是为了等数据库的主从同步过程

如果是写操作，先把缓存中的数据删除，然后更新数据库，最后再延时删除缓存中的数据，其中这个延时时间不好把控，在延时的过程中可能会出现脏数据，**并不能保证强一致性**

##### 方案一：强一致

强一致、性能低

读写锁：

- 共享锁：读锁readLock，加锁之后，其他线程可以==共享读==操作
- 排他锁：独占锁writeLock，加锁之后，==阻塞==其他线程==读写==操作

可以利用Redisson的读写锁实现

##### 方案二：异步最终一致性

- 利用MQ中间件，更新数据之后，通知缓存删除
- 利用Cancal中间件，不需要修改业务代码，伪装mysql的一个从节点，cancal通过读取binlog数据更新缓存

![image-20240803201832128](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408032018205.png)



------



#### 持久化

- RDB（Redis默认）
- AOF

##### RDB

RDB全称`Redis Backup File`（Redis数据备份文件），也叫Redis数据快照。就是把内存中的所有数据记录到磁盘中。当Redis实例故障重启后，从磁盘读取快照文件，恢复数据。

- save
- bgsave

```bash
# redis-cli命令
# 方案一，由Redis主进程来执行RDB，会阻塞所有命令
save 

# 方案二，开启子进程执行RDB，避免主进程受到影响
bgsave
```

可以在`redis.conf`文件配置RDB触发时机

```bash
# 查看当前 RDB save配置
config get save
# 默认为 每3600s修改1个key就保存 每300s...
3600 1 300 100 60 10000
# 修改触发时机配置
save 900 1 
```



###### RDB的执行原理

bgsave开始时会fork（微小阻塞）主进程得到子进程。子进程共享主进程的内存数据。完成fork后读取内存数据并写入RDB文件

fork采用的是 `copy-on-write`技术：

- 当主进程执行读操作时，访问共享内存
- 当主进程执行写操作时，则会拷贝一份数据，执行写操作

![image-20240803204729145](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408032047222.png)

> 页表：记录虚拟地址与物理地址的映射关系。克隆页表比起克隆实际数据要快，获取了页表相当于获取了实际数据

##### AOF

AOF全称为`Append Only File`（追加文件）。Redis处理的每一个**写命令**都会记录在AOF文件，可以看做是命令日志文件。

AOF默认是关闭的。需要修改`redis.conf`配置文件来开启AOF

```bash
# 是否开启AOF功能，默认是no
appendonly yes
# AOF文件的名称
appendfilename "appendonly.aof"
# AOF的记录频率，每一次都立即同步AOF文件
appendfsync always
```

| 配置项   | 刷盘时机     | 优点     | 缺点                       |
| -------- | :----------- | :------- | :------------------------- |
| always   | 同步刷盘     | 可靠性高 | 性能影响大                 |
| everysec | 每秒刷盘     | 性能适中 | 最多丢失1秒                |
| no       | 操作系统控制 | 性能最好 | 可靠性差，可能丢失大量数据 |

因为是记录命令，AOF文件会比RDB文件大得多，而AOF会记录对同一个key的多次写操作，但只有**最后一次写操作**才有意义，通过 `bgrewriteaof` 命令，可以让AOF文件执行重写功能，用最少的命令达到相同效果

可以在 `redis.conf` 配置AOF触发时机

```bash
# AOF文件比上次文件，增长超过多少百分比则触发重写
auto-aof-rewrite-percentage 100
# AOF文件体积最小多大以上才触发重写
auto-aof-rewrite-min-size 64mb
```

##### RDB与AOF

RDB和AOF各有优缺点，实际开发中往往会==结合==两者来使用

|                | RDB                                          | AOF                                                      |
| :------------- | :------------------------------------------- | :------------------------------------------------------- |
| 持久化方式     | 定时对整个内存做快照                         | 记录每一次执行的命令                                     |
| 数据完整性     | 不完整，两次备份之间可能会丢失               | 相对完整，取决于刷盘策略                                 |
| 文件大小       | 会有压缩，二进制文件，体积小                 | 记录命令，体积大                                         |
| 宕机回复速度   | 很快                                         | 慢                                                       |
| 数据恢复优先级 | 低，数据完整性不如AOF                        | 高，数据完整度高                                         |
| 系统资源占用   | 高，大量CPU和内存消耗                        | 低，主要是磁盘IO资源，但AOF重写时会占用大量CPU和内存资源 |
| 使用场景       | 可以容忍数分钟的数据丢失，追求更快的启动速度 | 对数据安全性要求较高的场景                               |

------



#### 过期策略

> Redis默认过期策略是==惰性删除==+==定期删除==，两者结合

Redis对数据设置的有效时间，数据过期以后，就需要将数据从内存中删除，可以按照不同的规则进行删除，这种删除规则被称之为数据的删除策略（数据过期策略）

- 惰性删除
- 定期删除

##### 惰性删除

惰性删除：设置该key过期时间后，我们不去管它，当需要该key时，我们再检查是否过期，如果过期就删除，反之返回该key

**优点**：对CPU友好，只会在使用该key时才进行过期检查，对于很多用不到的key不用浪费时间进行过期检查

**缺点**：对内存不友好，如果一个key已经过期，但一直没有使用，那么该key会一直存在内存中

##### 定期删除

定时删除：每隔一段时间，我们就对一些key进行检查，删除里面过期的key（从一定数量的数据库中取出一定数量的随机key进行检查，并删除其中的过期key）

两种模式

1. `SLOW`模式是定时任务，执行频率默认为10hz，每次不超过25ms，可通过`redis.conf`修改
2. `FAST`模式执行频率不固定，但每两次间隔不低于2ms，每次耗时不超过1ms

**优点**：可以通过限制删除操作执行的时长和频率来减少删除操作对CPU的影响，另外定期删除，也有效释放内存的占用

**缺点**：难以把控删除操作执行的时长和频率

------

#### 数据淘汰策略

数据淘汰策略：当Redis中的内存不够用时，此时再向Redis中添加新的key，那么Redis就会按照某种规则删除内存中的数据

1. noeviction（**默认**）：不淘汰任何key，但是内存满时不允许写入新数据
2. volatile-ttl：对设置了TTL的key，比较key剩余的TTL值，TTL越小越优先淘汰
3. allkeys-random：对全体key，随机淘汰
4. volatile-random：对设置了TTL的key，随机淘汰
5. allkeys-lru：对全体key，基于`LRU`算法（最近最少使用）进行淘汰
6. volatile-lru：对设置了TTL的key，基于LRU算法淘汰
7. allkeys-lfu：对全体key，基于`LFU`算法（最少频率使用）进行淘汰
8. volatile-lfu：对设置了TTL的key，基于LFU算法淘汰

##### 使用建议

![image-20240803214035393](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408032140492.png)

### 分布式锁

使用场景：集群情况下的定时任务、抢单秒杀、幂等性等场景

##### Redis分布式锁

Redis实现分布式锁主要利用 `setnx` 命令（SET if not exist）

```bash
# 一条命令，保证原子性
set key value nx ex 10
```

锁时间限制：锁续期

##### Redisson实现的分布式锁

![image-20240803221140632](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408032211716.png)加锁、设置过期时间等操作都是基于 `Lua` 脚本完成

```java
// 重入锁
RLock lock =  redisson.getLock("lockKey");
// 尝试获取锁的最大等待时间为100秒（期间会重试），锁的租约时间为10秒，锁自动释放
lock.trylock(100，10,TimeUnit.SECONDS);
...
lock.unlock();
```

##### Redisson可重入

可以重入，多个锁重入需要判断是否是当前线程，在redis中进行存储的时候使用的==hash结构==，来存储**线程信息和重入的次数**

##### Redisson主从一致性

RedLock（红锁）：不能只在一个redis实例上创建锁，应该是在多个redis实例上创建锁，没有主从节点概念，而是给所有redis节点加锁，有半数以上成功加锁才算成功，执行逻辑

- 实现复杂
- 性能差
- 远程维护繁琐

![image-20240801215300555](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408032223736.png)

> ==注意==：
>
> - Redlock保证高可用是**增加redis机器**，而不应该给每个redis节点再分配从节点，否则redis节点同步到从节点时，主挂了，导致投票失败，又会引发超卖问题
> - 机器应该为**奇数**，即3、5、7，而不应该4或者6这样，应为以半数投票，3和4没区别，还增加了资源的浪费
> - 由于AOF持久化，可能程序1获取了一把锁，而程序2有两把，即超过了半数，程序2依然可以执行操作

###### 建议使用Zoonkeeper

Zookeeper更偏向CAP原则中的CP，而Redis是AP，当Zk获取锁时，会先同步给从节点，当主节点挂了，底层ZAB机制会优先选取同步成功的从节点为主节点

## 其他面试题

- 集群
  - 主从
  - 哨兵
  - 集群
- 事务
- Redis为什么快