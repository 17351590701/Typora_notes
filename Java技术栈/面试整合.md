# Redis篇

- 缓存
  - 穿透、击穿、雪崩
  - 双写一致、持久化
  - 数据过期、淘汰策略
- 分布式锁
  - setnx、redisson
- 计数器 （incr）
- 保存token（string）
- 消息队列 （list）
- 延迟队列 （zset）
- 集群方案
  - 主从
  - 哨兵
  - 集群
- 事务
- Redis为什么快


## 缓存

### 缓存穿透

缓存穿透：查询一个**不存在**的数据，mysql查询不到数据也不会直接写入缓存，就会导致每次请求都查询数据库

#### 解决方案

###### 缓存空数据
![image-20240803171856089](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408031718207.png)

###### 布隆过滤器

通过bitmap（位图）一个以bit为单位的数组，数组中每个单元只能存储二进制数0或1，默认都为0，根据预热数据的id计算3次哈希值，将数组中对应位置变为1，查询数据时，如果3个对应位置都为1，则判断存在该数据![image-20240803172115383](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408031721467.png)

------



### 缓存击穿

缓存穿透：给某一个key设置了过期时间，当key过期的时候，恰好这时间点对这个key有大量的并发请求过来，这些并发请求可能会瞬间吧DB压垮

#### 解决方案

##### 互斥锁

当缓存失效时，不立即去load DB，而先使用如Redis的setnx去设置一个互斥锁，当操作成功返回时再进行load DB操作并设置缓存。互斥锁，防止大量请求都进入数据库操作。

- 强一致性
- 性能差

<img src="https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408031733182.png" alt="image-20240803173343122" style="zoom:67%;" />

##### 逻辑过期

将热点数据提前加入缓存中，且不设置过期时间，而是新增一个逻辑过期时间字段，可以返回旧数据（逻辑过期）

- 高可用
- 性能优



<img src="https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408031734975.png" alt="image-20240803173403905" style="zoom:67%;" />

------



### 缓存雪崩

缓存雪崩：指在同一时间段大量的缓存key同时失效或者Redis服务宕机，导致大量请求到达数据库，带来巨大压力

#### 解决方案

- 给不同key的TTL添加随机值
- 利用Redis集群提高服务的可用性（哨兵模式，集群模式）
- 给缓存业务添加降级限流策略（nginx或spring cloud gateway）
- 业务多级缓存（Guava或Caffeine）

------



### 双写一致性

redis作为缓存，与mysql数据库进行同步，根据业务背景要求选择

- 一致性要求高
- 允许延迟一致

#### 为什么不采用延时双删？

**延时双删：**先删缓存，再操作数据库，延时，再删除缓存

**删除两次缓存**是为了降低脏数据的出现

**延时删除**是为了等数据库的主从同步过程

如果是写操作，先把缓存中的数据删除，然后更新数据库，最后再延时删除缓存中的数据，其中这个延时时间不好把控，在延时的过程中可能会出现脏数据，**并不能保证强一致性**

#### 方案一：强一致

强一致、性能低

读写锁：

- 共享锁：读锁readLock，加锁之后，其他线程可以==共享读==操作
- 排他锁：独占锁writeLock，加锁之后，==阻塞==其他线程==读写==操作

可以利用Redisson的读写锁实现

#### 方案二：异步最终一致性

- 利用MQ中间件，更新数据之后，通知缓存删除
- 利用Cancal中间件，不需要修改业务代码，伪装mysql的一个从节点，cancal通过读取binlog数据更新缓存

![image-20240803201832128](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408032018205.png)



------



### 持久化

- RDB（Redis默认）
- AOF

#### RDB

RDB全称`Redis Backup File`（Redis数据备份文件），也叫Redis数据快照。就是把内存中的所有数据记录到磁盘中。当Redis实例故障重启后，从磁盘读取快照文件，恢复数据。

- save
- bgsave

```bash
# redis-cli命令
# 方案一，由Redis主进程来执行RDB，会阻塞所有命令
save 

# 方案二，开启子进程执行RDB，避免主进程受到影响
bgsave
```

可以在`redis.conf`文件配置RDB触发时机

```bash
# 查看当前 RDB save配置
config get save
# 默认为 每3600s修改1个key就保存 每300s...
3600 1 300 100 60 10000
# 修改触发时机配置
save 900 1 
```



##### RDB的执行原理

bgsave开始时会fork（微小阻塞）主进程得到子进程。子进程共享主进程的内存数据。完成fork后读取内存数据并写入RDB文件

fork采用的是 `copy-on-write`技术：

- 当主进程执行读操作时，访问共享内存
- 当主进程执行写操作时，则会拷贝一份数据，执行写操作

![image-20240803204729145](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408032047222.png)

> 页表：记录虚拟地址与物理地址的映射关系。克隆页表比起克隆实际数据要快，获取了页表相当于获取了实际数据

#### AOF

AOF全称为`Append Only File`（追加文件）。Redis处理的每一个**写命令**都会记录在AOF文件，可以看做是命令日志文件。

AOF默认是关闭的。需要修改`redis.conf`配置文件来开启AOF

```bash
# 是否开启AOF功能，默认是no
appendonly yes
# AOF文件的名称
appendfilename "appendonly.aof"
# AOF的记录频率，每一次都立即同步AOF文件
appendfsync always
```

| 配置项   | 刷盘时机     | 优点     | 缺点                       |
| -------- | :----------- | :------- | :------------------------- |
| always   | 同步刷盘     | 可靠性高 | 性能影响大                 |
| everysec | 每秒刷盘     | 性能适中 | 最多丢失1秒                |
| no       | 操作系统控制 | 性能最好 | 可靠性差，可能丢失大量数据 |

因为是记录命令，AOF文件会比RDB文件大得多，而AOF会记录对同一个key的多次写操作，但只有**最后一次写操作**才有意义，通过 `bgrewriteaof` 命令，可以让AOF文件执行重写功能，用最少的命令达到相同效果

可以在 `redis.conf` 配置AOF触发时机

```bash
# AOF文件比上次文件，增长超过多少百分比则触发重写
auto-aof-rewrite-percentage 100
# AOF文件体积最小多大以上才触发重写
auto-aof-rewrite-min-size 64mb
```

#### RDB与AOF

RDB和AOF各有优缺点，实际开发中往往会==结合==两者来使用

|                | RDB                                          | AOF                                                      |
| :------------- | :------------------------------------------- | :------------------------------------------------------- |
| 持久化方式     | 定时对整个内存做快照                         | 记录每一次执行的命令                                     |
| 数据完整性     | 不完整，两次备份之间可能会丢失               | 相对完整，取决于刷盘策略                                 |
| 文件大小       | 会有压缩，二进制文件，体积小                 | 记录命令，体积大                                         |
| 宕机回复速度   | 很快                                         | 慢                                                       |
| 数据恢复优先级 | 低，数据完整性不如AOF                        | 高，数据完整度高                                         |
| 系统资源占用   | 高，大量CPU和内存消耗                        | 低，主要是磁盘IO资源，但AOF重写时会占用大量CPU和内存资源 |
| 使用场景       | 可以容忍数分钟的数据丢失，追求更快的启动速度 | 对数据安全性要求较高的场景                               |

------



### 过期策略

> Redis默认过期策略是==惰性删除==+==定期删除==，两者结合

Redis对数据设置的有效时间，数据过期以后，就需要将数据从内存中删除，可以按照不同的规则进行删除，这种删除规则被称之为数据的删除策略（数据过期策略）

- 惰性删除
- 定期删除

#### 惰性删除

惰性删除：设置该key过期时间后，我们不去管它，当需要该key时，我们再检查是否过期，如果过期就删除，反之返回该key

**优点**：对CPU友好，只会在使用该key时才进行过期检查，对于很多用不到的key不用浪费时间进行过期检查

**缺点**：对内存不友好，如果一个key已经过期，但一直没有使用，那么该key会一直存在内存中

#### 定期删除

定时删除：每隔一段时间，我们就对一些key进行检查，删除里面过期的key（从一定数量的数据库中取出一定数量的随机key进行检查，并删除其中的过期key）

两种模式

1. `SLOW`模式是定时任务，执行频率默认为10hz，每次不超过25ms，可通过`redis.conf`修改
2. `FAST`模式执行频率不固定，但每两次间隔不低于2ms，每次耗时不超过1ms

**优点**：可以通过限制删除操作执行的时长和频率来减少删除操作对CPU的影响，另外定期删除，也有效释放内存的占用

**缺点**：难以把控删除操作执行的时长和频率

------

### 数据淘汰策略

数据淘汰策略：当Redis中的内存不够用时，此时再向Redis中添加新的key，那么Redis就会按照某种规则删除内存中的数据

1. noeviction（**默认**）：不淘汰任何key，但是内存满时不允许写入新数据
2. volatile-ttl：对设置了TTL的key，比较key剩余的TTL值，TTL越小越优先淘汰
3. allkeys-random：对全体key，随机淘汰
4. volatile-random：对设置了TTL的key，随机淘汰
5. allkeys-lru：对全体key，基于`LRU`算法（最近最少使用）进行淘汰
6. volatile-lru：对设置了TTL的key，基于LRU算法淘汰
7. allkeys-lfu：对全体key，基于`LFU`算法（最少频率使用）进行淘汰
8. volatile-lfu：对设置了TTL的key，基于LFU算法淘汰

#### 使用建议

![image-20240803214035393](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408032140492.png)

## 分布式锁

使用场景：集群情况下的定时任务、抢单秒杀、幂等性等场景

### Redis分布式锁

Redis实现分布式锁主要利用 `setnx` 命令（SET if not exist）

```bash
# 一条命令，保证原子性
set key value nx ex 10
```

锁时间限制：锁续期

### Redisson实现的分布式锁

![image-20240803221140632](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408032211716.png)

```xml
<!--包含了redisson依赖-->
<dependency>
   <groupId>org.redisson</groupId>
   <artifactId>redisson-spring-boot-starter</artifactId>
   <version>3.30.0</version>
</dependency>
```

加锁、设置过期时间等操作都是基于 `Lua` 脚本完成

```java
// 重入锁
RLock lock =  redisson.getLock("lockKey");
// 尝试获取锁的最大等待时间为30秒（期间会重试），锁的租约时间为10秒，锁自动释放
lock.trylock(30，10,TimeUnit.SECONDS);
...
lock.unlock();
```

### Redisson可重入

可以重入，多个锁重入需要判断是否是当前线程，在redis中进行存储的时候使用的==hash结构==，来存储**线程信息和重入的次数**

### Redisson主从一致性

RedLock（红锁）：不能只在一个redis实例上创建锁，应该是在多个redis实例上创建锁，没有主从节点概念，而是给所有redis节点加锁，有半数以上成功加锁才算成功，执行逻辑

- 实现复杂
- 性能差
- 远程维护繁琐

![image-20240801215300555](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408032223736.png)

> ==注意==：
>
> - Redlock保证高可用是**增加redis机器**，而不应该给每个redis节点再分配从节点，否则redis节点同步到从节点时，主挂了，导致投票失败，又会引发超卖问题
> - 机器应该为**奇数**，即3、5、7，而不应该4或者6这样，应为以半数投票，3和4没区别，还增加了资源的浪费
> - 由于AOF持久化，可能程序1获取了一把锁，而程序2有两把，即超过了半数，程序2依然可以执行操作

#### 建议使用Zoonkeeper

Zookeeper更偏向CAP原则中的CP，而Redis是AP，当Zk获取锁时，会先同步给从节点，当主节点挂了，底层ZAB机制会优先选取同步成功的从节点为主节点

## 集群

### 主从复制

==高可用==

单节点Redis的并发能力是有上限的，要进一步提高Redis的并发能力，就需要搭建主从集群，实现读写分离

![image-20240804164527780](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408041645932.png)

#### 主从数据同步原理

主从 ==全量同步==：

`Replication Id`：简称replid，是数据集的标记，id一致则说明是同一数据集。每一个master都有唯一的replid，slave则会继承master节点的replid

`offset`：偏移量，随着记录在`repl_baklog`中的数据增多而逐渐增大。slave完成同步时也会记录当前同步的offset，如果slave的offset小于master的offset，说明slave数据落后于master，需要更新

![image-20240804164903874](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408041649971.png)

主从 ==增量同步==（slave重启或后期数据变化）：

![image-20240804165312566](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408041653658.png)

### 哨兵的作用

==高并发==

Redis提供了哨兵（Sentinel）机制来实现主从集群的自动故障恢复。

- **监控**：Sentinel会不断检查master和slave是否按预期工作
- **自动故障恢复**：如果master故障，Sentinel会将一个slave提升为master。当故障实例恢复后也以新的master为主
- **通知**：Sentinel充当Redis客户端的服务发现来源，当集群发生故障转移时，会将最新信息推送给Redis客户端

![image-20240804165750343](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408041657438.png)

#### 服务状态监控

Sentinel基于心跳机制检测服务状态，每隔1秒向集群的每个实例发送ping命令

![image-20240804165937510](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408041659629.png)

> offset值越大，即已经同步的数据越接近原主节点的数据

#### Redis集群（哨兵模式）脑裂

集群脑裂：是由于主节点和从节点的sentinel处于不同的网络分区，使得sentinel没有能够心跳感知到主节点，所以通过选举的方式提升了一个从节点为主，这样就存在了两个master，就像大脑分裂了一样，这样会导致客户端还在老的master哪里写入数据，新节点无法同步数据，当网路恢复后，sentinel会将老的master降为从节点，这时再从新master同步数据，就会导致之前写入老master的数据丢失

**解决**：

修改`redis.conf`配置，设置最少的从节点数量以及缩短主从数据同步的延迟时间，达不到要求就拒绝请求，避免大量的数据丢失

### 分片集群

![image-20240804170859589](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408041708723.png)

#### 数据读写

Redis分片集群引入了哈希槽的概念，Redis集群有16384个哈希槽，每个key通过CRC16校验后对16384取模决定放置哪个槽，集群的每个节点负责一部分hash槽

![image-20240804171100509](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408041711620.png)

## Redis为什么快

### Redis是单线程的，但是为什么还那么快

- Redis是纯内存操作，执行速度非常快
- 采用单线程，避免不必要的上下文切换可竞争条件，多线程还要考虑线程安全问题
- 使用I/O多路复用模型，非阻塞IO

### I/O多路复用模型

Redis是春内存操作，执行速度非常快，它的性能瓶颈是==网络延迟==而不是执行速度，I/O多路复用模型主要是实现了高效的网络请求

- 用户空间和内核空间
- 常见的IO模型
  - 阻塞IO
  - 非阻塞IO
  - IO多路复用模型
- Redis网络模型

#### IO多路复用模型

![image-20240804172717926](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408041727031.png)

#### Redis网络模型

![image-20240804172738576](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408041727677.png)

<hr>

# Mysql篇

- 优化
  - 定位慢查询
  - SQL执行计划
  - 索引
    - 存储引擎
    - 索引底层数据结构
    - 聚簇索引和非聚簇索引
    - 索引创建原则
    - 索引失效场景
  - SQL优化经验
- 事务
  - 事务特性
  - 隔离级别
  - MVCC
- 主从同步
- 分库分表

## 优化
### 如何定位慢查询
- 调试工具：Arthas
- 运维工具：Prometheus、Skywalking
- Mysql自带慢日志查询
  
  ```sql
  slow_query_log = 1 # 开启慢查询日志（调制阶段）
  long_query_time = 2 # sql超过2s即记录为慢查询日志
  ```

### SQL执行计划（找到慢的原因）

可以采用`EXPLAIN`或者`DESC`命令获取Mysql如何执行select信息

```sql
explain select * from t_user where id = '1';
```

| id   | select_type | table  | partitions | type  | possible_keys | key     | key_len | ref   | rows | filtere | Extra |
| ---- | ----------- | ------ | ---------- | ----- | ------------- | ------- | ------- | ----- | ---- | ------- | ----- |
| 1    | STMPLE      | t_user | NULL       | const | PRIMARY       | PRIMARY | 98      | const | 1    | 100.0   | NULL  |

- type：sql的连接类型，性能由好到差为NULL、system、const、eq_ref、ref、range、index、all
  - const：主键查询
  - eq_ref：主键或唯一索引查询
  - ref：索引查询
  - range：索引，范围查询
  - index：索引树扫描
  - all：全盘扫描
- possible_key：当前sql可能会使用到的索引
- **key**：当前sql实际命中的索引
- **key_len**：索引占用的大小
- Extra：额外的优化建议，如果出现了回表的情况，可以尝试添加索引或修改返回字段来修复

### 索引

索引（index）是帮助Mysql==高效获取数据==的数据结构（有序）。在数据之外，数据库系统还维护满足特定查找算法的数据结构（B+树），这些数据结构以某种方式引用（指向）数据，这样就可以在这些数据结构上实现高级查找算法，这种数据结构就是索引

#### 数据结构对比

**二叉树**：在最坏情况下的二叉搜索树是一条线性的结构

**红黑树**：大数据量下，呈高瘦结构，层级多

**B树：**所有结点存放数据

![image-20240804200209819](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408042002922.png)

==B+树：==Mysql的InnoDB引擎默认采用的**B+树**的结构来存储索引

1. 阶数更多，路径更短
2. 磁盘读写代价B+树更低，非叶子结点只存储指针，叶子节点存储数据
3. B+树便于扫库和区间查询，叶子结点是一个==双向链表==

![image-20240804195812090](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408041958243.png)

#### 聚簇索引、非聚簇索引

##### 什么是聚簇索引、非聚簇索引

> 聚簇索引（聚焦索引）
>
> 非聚簇索引（二级索引）

| 分类     | 含义                                                     | 特点                 |
| :------- | :------------------------------------------------------- | -------------------- |
| 聚焦索引 | 将数据存储与索引放到了一块，B+树叶子结点保存了**行数据** | 必须有，而且只有一个 |
| 二级索引 | 将数据与索引分开存储，B+树叶子结点保存的是对应的**主键** | 可以存在多个         |

**聚集索引选取规则**：

1. 如果存在主键，主键索引就是聚焦索引
2. 如果不存在主键，将使用第一个唯一（UNIQUE）索引作为聚焦索引
3. 如果表没有主键或合适的唯一索引，则InnoDB会自动生成一个rowid作为隐藏的聚焦索引

![image-20240804200928767](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408042009902.png)

##### 回表查询

回表查询：通过二级索引查询到主键，根据主键到聚焦索引中查询整行数据

```sql
select * from user where name = 'Arm';
```

通过二级索引查询 `Arm` 找到主键为`10`，根据 `10`到聚焦索引中查询到该行数据

##### 覆盖索引

覆盖索引：是指查询使用了索引，并且需要返回的列，在该索引中已经全部能够找到

- 使用id查询，直接走聚焦索引查询，一次索引扫描，直接返回数据，性能高
- 如果返回的列中没有创建索引，有可能会触发回表查询，影响查询效率，尽量避免使用select*

![image-20240804205133523](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408042051682.png)

##### Mysql超大分页处理

在数据量比较大时，如果进行limit分页查询，在查询时，越往后，分页查询效率较低

```sql
select * from tb_sku limit 9000000,10;
```

大偏移量下查询到的前9000000行数据都需要丢弃，代价很大

**优化思路**：一般分页查询时，通过创建 ==覆盖索引==能够比较好的提高性能，可以通过 ==覆盖索引+子查询==的形式优化

```sql
select * 
from tb_sku t,
(select id from tb_sku order by id limit 9000000,10) a
where t.id = a.id;
```

==优化==：索引覆盖+子查询

> 先查询第1000001条数据的id，根据id来查询往后的数据

```mysql
select a.empno,
		 a.ename,
		 b.deptno
from emp e
	left join dept b
		on a.deptno = b.deptno
where a.id >= (select id from emp order by id limit 1000000,1)
order by a.id 
limit 50;
```

#### 索引创建原则

![image-20240804210832091](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408042108212.png)

#### 索引失效

给`tb_seller`创建联合索引，字段顺序：`name`、`status`、`address`

```sql
create index tb_seller_index on tb_seller (name,status,address);
```

##### 1.最左前缀法则

如果索引了多列，要遵守最左前缀法则。指的是查询从索引的最左前列开始，并且不跳过索引中的列，匹配最左前缀法则，走索引：

```sql
# 正常情况 key = tb_seller_index key_len = 303
explain select * from tb_seller where name = '小米科技';
# key_len = 309
explain select * from tb_seller where name = '小米科技' and status = '1';
# key_len = 612
explain select * from tb_seller where name = '小米科技' and status = '1' and address = '北京市';

# 违反失效情况 key = NULL
explain select * from tb_seller where status = '1';
explain select * from tb_seller where status = '1' and address = '北京市';

# 符合最左法则，跳跃了某一列，只有最左索引失效 key = tb_seller_index  key_len = 303
explain select * from tb_seller where name = '小米科技' and address = '北京市';
```

##### 2.范围查询

范围查询右边的列，不能使用索引

```sql
# key = tb_seller_index  key_len = 309
explain select * from tb_seller where name = '小米科技' and status > '1' and address = '北京市';
```

根据前面的两个字段 `name`，`status`查询时走索引的，但是最后一个条件`address`没有用到索引

##### 3.索引上运算操作

```sql
# key = null
explain select * from tb_seller where substring(name,3,2) = '科技';
```

##### 4.字符串不加单引号

(类型转换)

```sql
# key = tb_seller_index  key_len = 309
explain select * from tb_seller where name = '科技' and status = '0';
# key = tb_seller_index  key_len = 303
explain select * from tb_seller where name = '科技' and status = 0;
```

##### 5.模糊查询

以 `%` 开头的Like模糊查询，索引失效。如果仅仅是尾部模糊匹配，索引不会失效。如果头部模糊匹配，索引失效。

```sql
# key = null
explain select sellerid,name from tb_seller where name like '%程序员';
# key = tb_seller_index  key_len = 303
explain select sellerid,name from tb_seller where name like '程序员%';
```

### SQL优化经验

- 表的设计优化
- 索引优化
- SQL语句优化
- 主从复制，读写分离
- 分库分表

##### 表的设计优化

1. 设置合适的数值（tinyint int bigint），要根据实际情况选择
2. 设置合适的字符串类型（char varchar）char定长效率高，varchar可变长度，效率稍低

##### SQL语句优化

1. SELECT 语句务必指明字段名称（避免直接使用select *）

2. SQL语句要避免造成索引失效的写法

3. 尽量用`union all` 代替 `union`，union会多一次过滤去重，效率低

   ```sql
   select * from t_user where id > 2
   union all | union
   select * from t_user where id < 5
   ```

4. 避免在where子句中对字段进行表达式操作

5. `Join`优化 能用`innerjoin` 就不用`left join`、`right join`，如必须使用，一定要以小表为驱动，内连接会对两个表进行优化，优先把小表放到外边，把大表放到里边。left join、right join不会重新调整顺序

##### 主从复制、读写分离

如果数据库的使用场景读的操作比较多的时候，为了避免写的操作所造成的性能影响，可以采用读写分离的架构。

读写分离解决的是，数据库的写入，影响了查询的效率

![image-20240804214857832](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408042148965.png)

## 事务
事务是一组操作的集合，一个不可分割的工作单位，同成功同失败

### 事务的特性ACID

![image-20240805154339730](C:/Users/35747/AppData/Roaming/Typora/typora-user-images/image-20240805154339730.png)

### 事务隔离

##### 并发事务问题

![image-20240805154526696](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408051545851.png)

#### 事务隔离级别

Mysql默认隔离级别==可重复读==

![image-20240805154645484](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408051546642.png)

### undo_log与redo_log

**缓冲池（buffer pool）**：主内存中的一个区域，里面可以缓存磁盘上经常操作的真实数据，在执行增删改查操作时，先操作缓冲池中的数据（若缓冲池没有数据，则从磁盘加载并缓存），以一定频率刷新到磁盘，从而减少磁盘IO，加快处理速度

**数据页（page）**：是InnoDB存储引擎磁盘管理的最小单元，每个页的大小默认为16kb。页中存储的是行数据

![image-20240805155438095](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408051554235.png)

> 当服务器宕机后，内存中的数据可能同步失败了，数据也会丢失，所以需要`redo_log`日志记录对数据页的修改，同时同步到磁盘（顺序读写，速度快）

#### undo_log

![image-20240805155703468](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408051557670.png)

#### redo_log

![image-20240805155123620](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408051551806.png)

### MVCC

事务中的==隔离级别==是基于MVCC保证和实现的

MVCC（Multi-Version-Concurrency Controller），多版本并发控制。维护一个数据的多个版本，使得读写操作没有冲突。

![image-20240805160143035](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408051601177.png)

#### MVCC实现原理

- 隐式字段
  - DB_TRX_ID：事务ID，记录插入这条记录或最后一次修改该记录的事务ID，自增
  - DB_ROLL_PTR：回滚指针，指向这条记录的上个版本，用于配合undo_log，指向上一个版本

- undo_log日志
  - 回滚日志，存储老版本数据
  - 版本链：多个事务并行操作某一行记录，记录不同事务修改数据的版本，通过roll_pointer指针形成一个链表![image-20240805163048792](C:/Users/35747/AppData/Roaming/Typora/typora-user-images/image-20240805163048792.png)

- readView：解决的是一个事务查询选择版本的问题
  - 根据readView匹配规则和当前的一些事务id判断该访问哪个版本的数据
  - 不同的隔离级别快照读是不一样的，最终的访问结果也不一样
    - RC（ReadCommited）：每一次执行快照读时生成ReadView
    - RR（RepeatableRead）：仅在事务第一次执行快照读时生成ReadView，后续复用

## 主从同步

主从同步原理：

Mysql主从复制的核心就是二进制文件 ==binlog==

> 二进制文件（BINLOG）记录了所有的DDL（数据定义语言）语句和DML（数据操纵语言）语句，但不包括数据查询（SELECT，SHOW）语句

![image-20240805163737792](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408051637954.png)

## 分库分表

分库分表的时机

1. **前提**，项目业务数据逐渐增多，或业务发展比较迅速，单表的数据量达`1000w`或`20g`以后
2. 优化已解决不了性能问题（主从读写分离，查询索引...）
3. IO瓶颈（磁盘IO、网络IO）、CPU瓶颈（聚合查询、连接数太多）

### 拆分策略	

![image-20240805164530903](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408051645042.png)
#### 垂直拆分
==垂直分库==：以表为依据，根据业务将不同表拆分到不同库中
特点：

1. 按业务对数据分级管理、维护、监控、扩展
2. 在高并发下，提高磁盘IO和数据量连接数

==垂直分表==：以字段为依据，根据字段属性将不同字段拆分到不同表中

拆分规则：

- 把不常用的字段单独放在一张表中
- 把text、blob等大字段拆分出来放在附表中

特点：

1. 冷热数据分离
2. 减少IO过度争抢，两表互不影响

#### 水平拆分

==水平分库==：将一个库的**数据**拆分到多个库中

路由规则：

- 根据id节点取模，判断存储查询的库
- 按id范围路由，节点1（1-100w），节点2（100w-200w）...
- ...

特点：

1. 解决了单库大数量，高并发的性能瓶颈问题
2. 提高了系统的稳定性和可用性

==水平分表==：将一个表的数据拆分到多个表中（可以在同一个库中）

特点：

1. 优化单一表数据量过大而产生的性能问题
2. 避免IO争抢并减少锁表的几率

### 分库分表策略

分库之后的问题：

- 分布式事务一致性的问题
- 跨节点关联查询
- 跨节点分页、排序函数
- 主键避重

分库分表中间件：

- sharding-sphere
- mycat

# 框架

- Spring
	- Spring
		- Bean线程安全问题
		- AOP
			- 事务原理
			- 事务失效 
		- Bean的生命周期
		- 循环依赖
	- SpringMVC
		- 执行流程
	- Springboot
		- 自动配置原理
- Mybatis
	- 执行流程
	- 延迟加载
	- 一二级缓存

## Spring
### Spring
#### Bean线程安全问题

==单例bean==不是线程安全的

```java
@Service
@Scope("singleton")
public class UserServiceImpl implements UserService{

}
```
- singleton（默认）：bean在每个Spring IOC容器中只有一个实例
- prototype：一个bean的定义可以有多个实例

当多用户同时请求一个服务时，容器会给每一个请求分配一个线程，这是多个线程会并发执行该请求对应的业务逻辑（成员方法），如果该处理逻辑中有对该单例状态的修改（体现为单例的成员属性），则必须考虑线程同步问题。

因为一般在spring的bean中都是注入无状态的对象（能否被修改），没有线程安全问题，如果在bean中定义了可修改的成员变量，是要考虑线程安全问题的，可以使用多例或加锁来解决

```java
@RestController
@RequestMapping("/users")
public class UserController{
	//可修改的成员变量是非线程安全的
	private int count;

	@Resource // 无状态对象
	private UserService userService;

	@GetMapping("/{id}")
	public User getById(@PathVariable("id") long id){
		count++;
		System.out.println("count:"+count);
		userService.getById(id);
	}
}
```



#### AOP

AOP（Aspect Oriented Programming）：面向切面编程，用于那些与业务无关，但对多个对象产生影响的公共行为和逻辑，抽取公共模块服用，降低耦合

常见aop使用场景：

- 记录操作日志
- 缓存处理
- Spring中内置事务处理

Spring事务实现

- 编程式事务控制：需使用TransactionTemplate来实现，对业务代码有侵入性
- 声明式事务控制：声明式事务管理建立在AOP之上，本质是AOP功能，对方法前后进行拦截，在执行方法之前开启事务，在执行完目标方法后根据情况提交或者回滚

#### Spring事务失效

##### 1. 异常捕获处理

```java
@Transactional
public void update(Integer form,Integer to,Double money){
   try{
      ...
   }catch(Exception e){
      e.printStack();
   }
}
```

==原因==：事务通知只有捉到了目标抛出的异常，才能进行后续的回滚处理，如果自己处理掉了异常，事务通知无法知悉

解决：捕获异常后，抛出该异常 `throw new RuntimeException("转账失败")`

##### 2. 异常类型不正确

```java
@Transactional
public void update(Integer form,Integer to,Double money)throws FileFoundException{
   new FileInputStream("dddd");
}
```

==原因==：Spring默认只会回滚非检查异常（RuntimeException）

解决： `Transactional(rollback = Exception.class)`

##### 3. 方法为非public

```java
@Transactional
void update(Integer form,Integer to,Double money){
   
}
```

==原因==：Spring为方法创建代理、添加事务通知，前提条件都是该方法是public的

##### 4. final修饰的方法

```java
@Transactional
final void update(Integer form,Integer to,Double money){
   
}
```

==原因==：事务是AOP实现的，而AOP动态代理默认是使用JDK动态代理实现，通过子类继承，而非public和final修饰的方法，子类是无法继承的，所以动态生成的代理对象并没有重写aop过的方法

##### 5. 自调用方法

```java
@Service
public class UserServiceImpl implements UserService{
   @Transactional
   public void a(){

   }
   public void b(){
      a();
      this.a();
   }
}
```

==原因==：b()方法调用的是普通对象的a()方法，而非aop代理过的

解决：

1. 注入自身调用，`@Resource`依赖注入时，Spring 会确保最终注入的是经过 AOP 处理后的代理对象

   ```java
   @Resource
   private UserService userService;
   userService.a();
   ```

2. 获取当前代理对象`AopContext`

   ```java
    ((UserService) AopContext.currentProxy()).a()
   ```

3. 修改@Transactional注解的`propagation`属性，这样每次调用都会创建一个新的事务上下文，从而确保事务的独立性

   ```java
    @Transactional(propagation = Propagation.REQUIRES_NEW)
   ```

##### 6. 未被spring管理

  ```java
  //@Service
  ```

#### Bean的生命周期

1. BeanDefinition
2. 构造函数，实例化bean
3. 依赖注入
4. Aware接口（BeanNameAware、BeanFactoryAware、ApplicationContextAware）
5. BeanPostProcessor接口#`before`（前置的后置处理器）
6. 初始化方法（InitializingBean接口` afterpropertiesSet`   自定义init方法`@PostConstruct`）
7. BeanPostProcessor接口#`after` 
   - AOP动态代理
     - JDK动态代理
     - CGLIB动态代理
8. 销毁bean(`@PreDestroy`)

**BeanDefinition**：Spring容器在尽显实例化时，会将xml配置的`<bean>`的信息封装成一个BeanDefinition对象，Spring根据BeanDefinition来创建Bean对象，里面有很多的属性用来描述Bean

#### Bean的循环依赖

两个或两个以上的bean互相持有对方，形成闭环

```java
@Component
public class A{
   @Resource
   private B b ;
}

@Component
public class B{
   @Resource
   private A a;
}
```

##### 三级缓存

Spring解决循环依赖是通过三级缓存实现的

```java
public class DefaultSingletonBeanRegistry extends ...{
   private final Map<String,Object> singtonObjects = new ConcurrentHashMap(256); //一级缓存
   private final Map<String,Object> earlySingletonObjects = new ConcurrentHashMap(16); //二级缓存
   private final Map<String,ObjectFactory<?>> sigletonFactories = new HashMap(16); //三级缓存
}
```

| 缓存名称 | 原码名称              | 作用                                                         |
| -------- | --------------------- | ------------------------------------------------------------ |
| 一级缓存 | sigletonObjects       | 单例池，缓存已经经历了完整的生命周期，已经初始化完成的bean对象 |
| 二级缓存 | earlySingletonObjects | 缓存早期的bean对象（生命周期未走完）                         |
| 三级缓存 | singletonFactories    | 缓存的是ObjectFactory，表示对象工厂，用来创建某个对象的      |

一级缓存+二级缓存能解决一般对象的循环依赖问题，但如果实例化的是一个aop代理对象，那还需要三级缓存

![image-20240805210306764](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408052103978.png)

> singletonFactories对象工厂，生产普通对象和代理对象

##### 构造方法注入循环依赖问题

Spring提供的三级缓存并不能解决构造方法形成的循环依赖

```java
@Component
public class A{
   private B b;
   public A(){
      System.out.println("A的构造方法");
      this.b = b;
   }
}

@Component
public class B{
   private A a;
   public B(){
      System.out.println("B的构造方法");
      this.a = a;
   }
}
```

==解决==：A的构造方法上 `@Lazy` 延迟加载实例化

```java
public A(@Lazy B b){
   System.out.println("A的构造方法");
   this.b = b;
}
```

### SpringMVC执行流程
- 视图阶段（老旧JSP等）
- 前后端分离阶段（接口开发、异步）

#### 视图阶段（JSP）

1. 用户发送请求到前端控制器 DispatcherServlet（前端控制器）
2. DispatcherServlet收到请求调用HandlerMapping（处理映射器）
3. HandlerMapping找到具体的处理器（接口方法），生产处理器对象以及处理器拦截器（如果有），再一起返回给DispatcherServelt
4. DispatcherServler调用HandlerAdapter（处理适配器）
5. HandlerAdapter经过适配器调用具体的处理器（Handler/Controller）
6. Controller执行完成返回ModelAndView对象
7. HandlerAdapter将结果ModelAndView返回给DispatcherServlet
8. DispatcherServlet将ModelAndView传给ViewResolver（视图解析器）
9. ViewResolver解析后返回具体的View（视图）
10. DispatcherServlet根据View进行渲染视图（模型数据填充至视图中）
11. DispatcherServler响应

![image-20240805213322296](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408052133492.png)

#### 前后端分离阶段

1. 用户发送请求到前端控制器 DispatcherServlet（前端控制器）
2. DispatcherServlet收到请求调用HandlerMapping`处理映射器）
3. HandlerMapping找到具体的处理器（接口方法），生产处理器对象以及处理器拦截器（如果有），再一起返回给DispatcherServelt
4. DispatcherServler调用HandlerAdapter（处理适配器）
5. HandlerAdapter经过适配器调用具体的处理器（Handler/Controller）
6. 方法上添加了`@ResponseBody`
7. 通过HttpMessageConverter来返回结果转化为JSON并响应

![image-20240805213419575](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408052134763.png)

### Springboot自动配置

- `@SpringBootApplication`
  - `@SpringBootConfiguration`：与`@Configuration`作用相同，声明当前类为配置类
  - `@ComponentScan`：组件扫描，默认扫描当前引导类所在包及其子包
  - `@EnableAutoConfiguration`：SpringBoot实现自动化配置的==核心注解==
    - `@AutoConfigurationPackage`
    - `@Import({AutoConifgurationImportSelector.class})`

通过`@Import`导入对应的配置选择器，其内部就是读取了该项目和该醒目引用的Jar包的classpath路径下的META-INF/spring.factories文件中的**自动配置类**的全类名。在这些配置类中所定义的Bean会根据条件注解（`@Conditionxxx`）所指定的条件来决定是否需要将其导入Spring容器中
### Spring框架常见注解
#### Spring

| 注解                                           | 说明                                             |
| ---------------------------------------------- | ------------------------------------------------ |
| @Component、@Controller、@Service、@Repository | 使用在类上用于实例化Bean                         |
| @Autowired                                     | 使用在字段上用于根据类型依赖注入                 |
| @Qualifier                                     | 结合@Autowired一起使用，根据名称依赖注入         |
| @Scope                                         | 标注Bean的作用范围                               |
| @Configuration                                 | 指定为Spring配置类，创建容器时会从该类上加载注解 |
| @ComponentScan                                 | 指定Spring初始化容器要扫描的包                   |
| @Bean                                          | 使用在方法上，标注方法返回值存储到Spring容器中   |
| @Import                                        | 使用@Import导入的类会被Spring加载到IOC容器中     |
| @Aspect、@Before、@After、@Around、@Pointcot   | 用于切面编程（AOP）                              |



#### SpringMVC

| 注解            | 说明                                             |
| --------------- | ------------------------------------------------ |
| @RequestMapping | 用于映射请求路径                                 |
| @RequestBody    | 接受http请求的json数据，将json数据转化为java对象 |
| @RequestParam   | 接受请求参数                                     |
| @PathVariable   | 从请求路径获取参数（/users/{id}）                |
| @ResponseBody   | 将响应的java对象转化为json数据给客户端           |
| @RequestHeader  | 指定请求头数据                                   |
| @RestController | @Controller+@ResponseBody                        |



#### Springboot

| 注解                     | 说明                                       |
| ------------------------ | ------------------------------------------ |
| @SpringBootConfiguration | 组合@Configuration注解，实现配置文件的功能 |
| @EnableAutoConfiguration | 打开自动配置的功能，也可以关闭某个自动配置 |
| @ComponentScan           | Spring组件扫描                             |

## Mybatis

### Mybatis执行流程

1. 读取Mybatis配置文件：mybatis-config.xml加载运行环境和映射文件
   1. 数据库、用户名、密码等环境
   2. 指定UserMapper.xml，Mapper扫描包路径
2. 构造会话工厂SqlSessionFactory（全局只有一个）
3. 会话工厂创建SqlSession对象（包含了执行SQL语句的所有方法）
4. 真正操作数据库的接口，Executor执行器，同时负责查询缓存的维护
5. Executor接口的执行方法中有一个MappedStatement类型的参数，封装了映射信息
   1. Mapper.xml名`resource`，方法名 `id`、`sql`语句、`resultMaps`返回结果等
6. 输入参数映射（java类型-->数据库类型）
7. 输出结果映射（数据库类型-->java类型）

### Mybatis延迟加载

Mybatis支持延迟加载，默认关闭

延迟加载：需要用到数据时才加载，不需要用到时，不加载数据

![image-20240805223110198](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408052231404.png)

在Mybatis配置文件中`mybatis-config.xml`，可以配置是否启用全局延迟加载`lazyLoadingEnabled=true|false`默认是关闭

#### 延迟加载原理

![image-20240805223208099](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408052232323.png)

### 一级、二级缓存

- 本地缓存：基于PerpetualCache，本质是一个HashMap
- 一级缓存：作用域是sessino级别
- 二级缓存：作用域是namespace和mapper的作用域，不依赖seesion（SqlSession）

#### 一级缓存（默认）

一级缓存：基于PerpetualCahce的HashMap本地缓存，其存储作用域为Session，当Session进行flush或close之后，该Session中的所有Cache将清空

```java
String resource = "mybatis-config.xml";
InputStream inputStream = Resources.getResourceAsStream(resource);
SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream);

SqlSession sqlSession = sqlSessionFacotry.openSession();
UserMapper userMapper1 = sqlSession.getMapper(UserMapper.class);
UserMapper userMapper2 = sqlSession.getMapper(UserMapper.class);

//使用了同一个sqlSession，只会执行一次sql,第二次直接从缓存中获取数据
User user = userMapper1.selectById(6);
User user = userMapper2.selectById(6);

sqlSession.close();
```

#### 二级缓存

二级缓存基于namespace和mapper的作用域，不是依赖于SqlSession，默认也是采用PerpetualCache，HashMap存储

不开启二级缓存时：

```java
SqlSession sqlSession1 = sqlSessionFacotry.openSession();
UserMapper userMapper1 = sqlSession1.getMapper(UserMapper.class);
User user = userMapper1.selectById(6);
sqlSession1.close();
// 两个SqlSession，查询了两次sql
SqlSession sqlSession2 = sqlSessionFacotry.openSession();
UserMapper userMapper2 = sqlSession2.getMapper(UserMapper.class);
User user = userMapper2.selectById(6);
sqlSession.close();

```

二级缓存默认是关闭的，开启方式：

1. 全局配置文件

   ```xml
   <settings>
   	<setting name="cacheEnable" value="true"/>
   </settings>
   ```

2. 映射文件mapper.xml，使用`<cache/>`标签让当前mapper生效二级缓存

开启二级缓存后，上述只会执行一次`sql`语句

==注意事项==：

![image-20240805225030635](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408052250840.png)

**二级缓存清理缓存数据**：当某一个作用域（一级缓存Session/二级缓存Namespace）进行了==增删改==操作后，默认该作用域下所有select中的缓存将被clear

# 微服务篇

- Spring cloud
  - 服务注册
    - nacos
    - eureka
  - 负载均衡
    - Ribbon负载均衡策略
    - 自定义负载均衡
  - 熔断、降级
  - 监控
    - skywalking
- 业务相关
  - 限流
    - 漏桶算法
    - 令牌桶算法
  - 分布式事务
    - 分布式理论CAP
    - 分布式事务解决方案
    - seata
  - 分布式服务接口幂等性
  - 分布式任务调度
    - xxl-job

## SpringCloud
 ==Spring五大组件==
1. 注册中心：Nacos、Eureka
2. 负载均衡：Ribbon、spring-cloud-loadbalancer
3. 服务调用：Feign
4. 服务保护：Sentinel、Hystrix
5. 服务网关：Gateway、Zuul

### 服务注册和发现
nacos、eureka、zookeeper
#### 如何实现
以eureka作为注册中心为例
**服务注册**：服务提供者需要把自己的信息注册到eureka，由eureka来保存这些信息，比如服务名称、ip、端口等等
**服务发现**：消费者向eureka拉取服务列表信息，如果服务提供者有集群，则消费者会利用负载均衡算法，选择一个发起调用
**服务监控**：服务提供者会每隔30s向eureka发送心跳，报告健康状态，如果eureka服务90s没收到心跳，则从eureka剔除该服务
#### nacos与eureka区别
**共同点**：

1. 都支持服务注册和服务拉取
2. 都支持服务提供者心跳方式做健康检测

**区别**：

1. Nacos支持服务端主动检测提供者状态：临时实例采用心跳模式，非临时实力采用主动监测模式
2. 临时实例心跳不正常会被剔除，非临时实例则不会被剔除
3. Nacos支持服务列表变更的消息推送模式，服务列表更新更及时
4. Nacos集群默认采用AP方式，当集群中存在非临时实例时，采用CP模式；Eureka采用AP方式

> [!NOTE] 
> Nacos还提供了**配置中心**，eureka则只有注册中心

![image.png](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408061045181.png)

### 负载均衡
负载均衡Ribbon，发起远程调用Feign就会使用Ribbon
#### Ribbon负载均衡流程
![image.png](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408061055026.png)
#### 负载均衡策略
1. **RoundRobinRule**：简单轮询
2. **WeightedResponseTimeRule**：按照权重选择，响应时间越长，权重越小
3. **RandomRule**：随机选择
4. BestAvailableRule：忽略短路的服务器，选择并发数较低的
5. RetryRule：重试机制的选择逻辑
6. AvailablityFilteringRule：可用性敏感策略，先过滤非健康的，再连接数较小的
7. **ZonAvoidanceRule**（Ribbon默认）：以区域可用的服务器为基础进行服务器的选择，使用Zone对服务器进行分类，这个Zone可以理解为一个机房等，而后再对Zone内的服务进行轮询

##### 自定义负载均衡策略
- 创建类实现`IRule`接口，可以指定负载均衡策略（全局）

  ```java
  @Bean
  public IRule randomRule(){
     return new RandomRule();
  }
  ```
- 在客户端的配置文件中，可以配置某一个服务调用负载均衡策略（局部）

  ```yml
  userservice:
  	ribbon:
  		NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule #负载均衡规则
  ```

  

### 服务雪崩
服务雪崩：一个服务失败，导致整条链路的服务都失败的情形
#### 服务降级
