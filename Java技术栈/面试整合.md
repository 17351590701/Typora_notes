# Redis篇

- 缓存
  - 穿透、击穿、雪崩
  - 双写一致、持久化
  - 数据过期、淘汰策略
- 分布式锁
  - setnx、redisson
- 计数器 （incr）
- 保存token（string）
- 消息队列 （list）
- 延迟队列 （zset）
- 集群方案
  - 主从
  - 哨兵
  - 集群
- 事务
- Redis为什么快

## 缓存

### 缓存穿透

缓存穿透：查询一个**不存在**的数据，mysql查询不到数据也不会直接写入缓存，就会导致每次请求都查询数据库

#### 解决方案

###### 缓存空数据![image-20240803171856089](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408031718207.png)

###### 布隆过滤器

通过bitmap（位图）一个以bit为单位的数组，数组中每个单元只能存储二进制数0或1，默认都为0，根据预热数据的id计算3次哈希值，将数组中对应位置变为1，查询数据时，如果3个对应位置都为1，则判断存在该数据![image-20240803172115383](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408031721467.png)

------



### 缓存击穿

缓存穿透：给某一个key设置了过期时间，当key过期的时候，恰好这时间点对这个key有大量的并发请求过来，这些并发请求可能会瞬间吧DB压垮

#### 解决方案

##### 互斥锁

当缓存失效时，不立即去load DB，而先使用如Redis的setnx去设置一个互斥锁，当操作成功返回时再进行load DB操作并设置缓存。互斥锁，防止大量请求都进入数据库操作。

- 强一致性
- 性能差

<img src="https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408031733182.png" alt="image-20240803173343122" style="zoom:67%;" />

##### 逻辑过期

将热点数据提前加入缓存中，且不设置过期时间，而是新增一个逻辑过期时间字段，可以返回旧数据（逻辑过期）

- 高可用
- 性能优



<img src="https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408031734975.png" alt="image-20240803173403905" style="zoom:67%;" />

------



### 缓存雪崩

缓存雪崩：指在同一时间段大量的缓存key同时失效或者Redis服务宕机，导致大量请求到达数据库，带来巨大压力

#### 解决方案

- 给不同key的TTL添加随机值
- 利用Redis集群提高服务的可用性（哨兵模式，集群模式）
- 给缓存业务添加降级限流策略（nginx或spring cloud gateway）
- 业务多级缓存（Guava或Caffeine）

------



### 双写一致性

redis作为缓存，与mysql数据库进行同步，根据业务背景要求选择

- 一致性要求高
- 允许延迟一致

#### 为什么不采用延时双删？

**延时双删：**先删缓存，再操作数据库，延时，再删除缓存

**删除两次缓存**是为了降低脏数据的出现

**延时删除**是为了等数据库的主从同步过程

如果是写操作，先把缓存中的数据删除，然后更新数据库，最后再延时删除缓存中的数据，其中这个延时时间不好把控，在延时的过程中可能会出现脏数据，**并不能保证强一致性**

#### 方案一：强一致

强一致、性能低

读写锁：

- 共享锁：读锁readLock，加锁之后，其他线程可以==共享读==操作
- 排他锁：独占锁writeLock，加锁之后，==阻塞==其他线程==读写==操作

可以利用Redisson的读写锁实现

#### 方案二：异步最终一致性

- 利用MQ中间件，更新数据之后，通知缓存删除
- 利用Cancal中间件，不需要修改业务代码，伪装mysql的一个从节点，cancal通过读取binlog数据更新缓存

![image-20240803201832128](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408032018205.png)



------



### 持久化

- RDB（Redis默认）
- AOF

#### RDB

RDB全称`Redis Backup File`（Redis数据备份文件），也叫Redis数据快照。就是把内存中的所有数据记录到磁盘中。当Redis实例故障重启后，从磁盘读取快照文件，恢复数据。

- save
- bgsave

```bash
# redis-cli命令
# 方案一，由Redis主进程来执行RDB，会阻塞所有命令
save 

# 方案二，开启子进程执行RDB，避免主进程受到影响
bgsave
```

可以在`redis.conf`文件配置RDB触发时机

```bash
# 查看当前 RDB save配置
config get save
# 默认为 每3600s修改1个key就保存 每300s...
3600 1 300 100 60 10000
# 修改触发时机配置
save 900 1 
```



##### RDB的执行原理

bgsave开始时会fork（微小阻塞）主进程得到子进程。子进程共享主进程的内存数据。完成fork后读取内存数据并写入RDB文件

fork采用的是 `copy-on-write`技术：

- 当主进程执行读操作时，访问共享内存
- 当主进程执行写操作时，则会拷贝一份数据，执行写操作

![image-20240803204729145](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408032047222.png)

> 页表：记录虚拟地址与物理地址的映射关系。克隆页表比起克隆实际数据要快，获取了页表相当于获取了实际数据

#### AOF

AOF全称为`Append Only File`（追加文件）。Redis处理的每一个**写命令**都会记录在AOF文件，可以看做是命令日志文件。

AOF默认是关闭的。需要修改`redis.conf`配置文件来开启AOF

```bash
# 是否开启AOF功能，默认是no
appendonly yes
# AOF文件的名称
appendfilename "appendonly.aof"
# AOF的记录频率，每一次都立即同步AOF文件
appendfsync always
```

| 配置项   | 刷盘时机     | 优点     | 缺点                       |
| -------- | :----------- | :------- | :------------------------- |
| always   | 同步刷盘     | 可靠性高 | 性能影响大                 |
| everysec | 每秒刷盘     | 性能适中 | 最多丢失1秒                |
| no       | 操作系统控制 | 性能最好 | 可靠性差，可能丢失大量数据 |

因为是记录命令，AOF文件会比RDB文件大得多，而AOF会记录对同一个key的多次写操作，但只有**最后一次写操作**才有意义，通过 `bgrewriteaof` 命令，可以让AOF文件执行重写功能，用最少的命令达到相同效果

可以在 `redis.conf` 配置AOF触发时机

```bash
# AOF文件比上次文件，增长超过多少百分比则触发重写
auto-aof-rewrite-percentage 100
# AOF文件体积最小多大以上才触发重写
auto-aof-rewrite-min-size 64mb
```

#### RDB与AOF

RDB和AOF各有优缺点，实际开发中往往会==结合==两者来使用

|                | RDB                                          | AOF                                                      |
| :------------- | :------------------------------------------- | :------------------------------------------------------- |
| 持久化方式     | 定时对整个内存做快照                         | 记录每一次执行的命令                                     |
| 数据完整性     | 不完整，两次备份之间可能会丢失               | 相对完整，取决于刷盘策略                                 |
| 文件大小       | 会有压缩，二进制文件，体积小                 | 记录命令，体积大                                         |
| 宕机回复速度   | 很快                                         | 慢                                                       |
| 数据恢复优先级 | 低，数据完整性不如AOF                        | 高，数据完整度高                                         |
| 系统资源占用   | 高，大量CPU和内存消耗                        | 低，主要是磁盘IO资源，但AOF重写时会占用大量CPU和内存资源 |
| 使用场景       | 可以容忍数分钟的数据丢失，追求更快的启动速度 | 对数据安全性要求较高的场景                               |

------



### 过期策略

> Redis默认过期策略是==惰性删除==+==定期删除==，两者结合

Redis对数据设置的有效时间，数据过期以后，就需要将数据从内存中删除，可以按照不同的规则进行删除，这种删除规则被称之为数据的删除策略（数据过期策略）

- 惰性删除
- 定期删除

#### 惰性删除

惰性删除：设置该key过期时间后，我们不去管它，当需要该key时，我们再检查是否过期，如果过期就删除，反之返回该key

**优点**：对CPU友好，只会在使用该key时才进行过期检查，对于很多用不到的key不用浪费时间进行过期检查

**缺点**：对内存不友好，如果一个key已经过期，但一直没有使用，那么该key会一直存在内存中

#### 定期删除

定时删除：每隔一段时间，我们就对一些key进行检查，删除里面过期的key（从一定数量的数据库中取出一定数量的随机key进行检查，并删除其中的过期key）

两种模式

1. `SLOW`模式是定时任务，执行频率默认为10hz，每次不超过25ms，可通过`redis.conf`修改
2. `FAST`模式执行频率不固定，但每两次间隔不低于2ms，每次耗时不超过1ms

**优点**：可以通过限制删除操作执行的时长和频率来减少删除操作对CPU的影响，另外定期删除，也有效释放内存的占用

**缺点**：难以把控删除操作执行的时长和频率

------

### 数据淘汰策略

数据淘汰策略：当Redis中的内存不够用时，此时再向Redis中添加新的key，那么Redis就会按照某种规则删除内存中的数据

1. noeviction（**默认**）：不淘汰任何key，但是内存满时不允许写入新数据
2. volatile-ttl：对设置了TTL的key，比较key剩余的TTL值，TTL越小越优先淘汰
3. allkeys-random：对全体key，随机淘汰
4. volatile-random：对设置了TTL的key，随机淘汰
5. allkeys-lru：对全体key，基于`LRU`算法（最近最少使用）进行淘汰
6. volatile-lru：对设置了TTL的key，基于LRU算法淘汰
7. allkeys-lfu：对全体key，基于`LFU`算法（最少频率使用）进行淘汰
8. volatile-lfu：对设置了TTL的key，基于LFU算法淘汰

#### 使用建议

![image-20240803214035393](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408032140492.png)

## 分布式锁

使用场景：集群情况下的定时任务、抢单秒杀、幂等性等场景

### Redis分布式锁

Redis实现分布式锁主要利用 `setnx` 命令（SET if not exist）

```bash
# 一条命令，保证原子性
set key value nx ex 10
```

锁时间限制：锁续期

### Redisson实现的分布式锁

![image-20240803221140632](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408032211716.png)

```xml
<!--包含了redisson依赖-->
<dependency>
   <groupId>org.redisson</groupId>
   <artifactId>redisson-spring-boot-starter</artifactId>
   <version>3.30.0</version>
</dependency>
```

加锁、设置过期时间等操作都是基于 `Lua` 脚本完成

```java
// 重入锁
RLock lock =  redisson.getLock("lockKey");
// 尝试获取锁的最大等待时间为30秒（期间会重试），锁的租约时间为10秒，锁自动释放
lock.trylock(30，10,TimeUnit.SECONDS);
...
lock.unlock();
```

### Redisson可重入

可以重入，多个锁重入需要判断是否是当前线程，在redis中进行存储的时候使用的==hash结构==，来存储**线程信息和重入的次数**

### Redisson主从一致性

RedLock（红锁）：不能只在一个redis实例上创建锁，应该是在多个redis实例上创建锁，没有主从节点概念，而是给所有redis节点加锁，有半数以上成功加锁才算成功，执行逻辑

- 实现复杂
- 性能差
- 远程维护繁琐

![image-20240801215300555](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408032223736.png)

> ==注意==：
>
> - Redlock保证高可用是**增加redis机器**，而不应该给每个redis节点再分配从节点，否则redis节点同步到从节点时，主挂了，导致投票失败，又会引发超卖问题
> - 机器应该为**奇数**，即3、5、7，而不应该4或者6这样，应为以半数投票，3和4没区别，还增加了资源的浪费
> - 由于AOF持久化，可能程序1获取了一把锁，而程序2有两把，即超过了半数，程序2依然可以执行操作

#### 建议使用Zoonkeeper

Zookeeper更偏向CAP原则中的CP，而Redis是AP，当Zk获取锁时，会先同步给从节点，当主节点挂了，底层ZAB机制会优先选取同步成功的从节点为主节点

## 集群

### 主从复制

==高可用==

单节点Redis的并发能力是有上限的，要进一步提高Redis的并发能力，就需要搭建主从集群，实现读写分离

![image-20240804164527780](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408041645932.png)

#### 主从数据同步原理

主从 ==全量同步==：

`Replication Id`：简称replid，是数据集的标记，id一致则说明是同一数据集。每一个master都有唯一的replid，slave则会继承master节点的replid

`offset`：偏移量，随着记录在`repl_baklog`中的数据增多而逐渐增大。slave完成同步时也会记录当前同步的offset，如果slave的offset小于master的offset，说明slave数据落后于master，需要更新

![image-20240804164903874](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408041649971.png)

主从 ==增量同步==（slave重启或后期数据变化）：

![image-20240804165312566](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408041653658.png)

### 哨兵的作用

==高并发==

Redis提供了哨兵（Sentinel）机制来实现主从集群的自动故障恢复。

- **监控**：Sentinel会不断检查master和slave是否按预期工作
- **自动故障恢复**：如果master故障，Sentinel会将一个slave提升为master。当故障实例恢复后也以新的master为主
- **通知**：Sentinel充当Redis客户端的服务发现来源，当集群发生故障转移时，会将最新信息推送给Redis客户端

![image-20240804165750343](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408041657438.png)

#### 服务状态监控

Sentinel基于心跳机制检测服务状态，每隔1秒向集群的每个实例发送ping命令

![image-20240804165937510](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408041659629.png)

> offset值越大，即已经同步的数据越接近原主节点的数据

#### Redis集群（哨兵模式）脑裂

集群脑裂：是由于主节点和从节点的sentinel处于不同的网络分区，使得sentinel没有能够心跳感知到主节点，所以通过选举的方式提升了一个从节点为主，这样就存在了两个master，就像大脑分裂了一样，这样会导致客户端还在老的master哪里写入数据，新节点无法同步数据，当网路恢复后，sentinel会将老的master降为从节点，这时再从新master同步数据，就会导致之前写入老master的数据丢失

**解决**：

修改`redis.conf`配置，设置最少的从节点数量以及缩短主从数据同步的延迟时间，达不到要求就拒绝请求，避免大量的数据丢失

### 分片集群

![image-20240804170859589](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408041708723.png)

#### 数据读写

Redis分片集群引入了哈希槽的概念，Redis集群有16384个哈希槽，每个key通过CRC16校验后对16384取模决定放置哪个槽，集群的每个节点负责一部分hash槽

![image-20240804171100509](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408041711620.png)

## Redis为什么快

### Redis是单线程的，但是为什么还那么快

- Redis是纯内存操作，执行速度非常快
- 采用单线程，避免不必要的上下文切换可竞争条件，多线程还要考虑线程安全问题
- 使用I/O多路复用模型，非阻塞IO

### I/O多路复用模型

Redis是春内存操作，执行速度非常快，它的性能瓶颈是==网络延迟==而不是执行速度，I/O多路复用模型主要是实现了高效的网络请求

- 用户空间和内核空间
- 常见的IO模型
  - 阻塞IO
  - 非阻塞IO
  - IO多路复用模型
- Redis网络模型

#### IO多路复用模型

![image-20240804172717926](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408041727031.png)

#### Redis网络模型

![image-20240804172738576](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408041727677.png)

<hr>

# Mysql篇

- 优化
  - 定位慢查询
  - SQL执行计划
  - 索引
    - 存储引擎
    - 索引底层数据结构
    - 聚簇索引和非聚簇索引
    - 索引创建原则
    - 索引失效场景
  - SQL优化经验
- 事务
  - 事务特性
  - 隔离级别
  - MVCC
- 主从同步
- 分库分表

## 优化
### 如何定位慢查询
- 调试工具：Arthas
- 运维工具：Prometheus、Skywalking
- Mysql自带慢日志查询
  
  ```sql
  slow_query_log = 1 # 开启慢查询日志（调制阶段）
  long_query_time = 2 # sql超过2s即记录为慢查询日志
  ```

### SQL执行计划（找到慢的原因）

可以采用`EXPLAIN`或者`DESC`命令获取Mysql如何执行select信息

```sql
explain select * from t_user where id = '1';
```

| id   | select_type | table  | partitions | type  | possible_keys | key     | key_len | ref   | rows | filtere | Extra |
| ---- | ----------- | ------ | ---------- | ----- | ------------- | ------- | ------- | ----- | ---- | ------- | ----- |
| 1    | STMPLE      | t_user | NULL       | const | PRIMARY       | PRIMARY | 98      | const | 1    | 100.0   | NULL  |

- type：sql的连接类型，性能由好到差为NULL、system、const、eq_ref、ref、range、index、all
  - const：主键查询
  - eq_ref：主键或唯一索引查询
  - ref：索引查询
  - range：索引，范围查询
  - index：索引树扫描
  - all：全盘扫描
- possible_key：当前sql可能会使用到的索引
- **key**：当前sql实际命中的索引
- **key_len**：索引占用的大小
- Extra：额外的优化建议，如果出现了回表的情况，可以尝试添加索引或修改返回字段来修复

### 索引

索引（index）是帮助Mysql==高效获取数据==的数据结构（有序）。在数据之外，数据库系统还维护满足特定查找算法的数据结构（B+树），这些数据结构以某种方式引用（指向）数据，这样就可以在这些数据结构上实现高级查找算法，这种数据结构就是索引

#### 数据结构对比

**二叉树**：在最坏情况下的二叉搜索树是一条线性的结构

**红黑树**：大数据量下，呈高瘦结构，层级多

**B树：**所有结点存放数据

![image-20240804200209819](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408042002922.png)

==B+树：==Mysql的InnoDB引擎默认采用的**B+树**的结构来存储索引

1. 阶数更多，路径更短
2. 磁盘读写代价B+树更低，非叶子结点只存储指针，叶子节点存储数据
3. B+树便于扫库和区间查询，叶子结点是一个==双向链表==

![image-20240804195812090](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408041958243.png)

#### 聚簇索引、非聚簇索引

##### 什么是聚簇索引、非聚簇索引

> 聚簇索引（聚焦索引）
>
> 非聚簇索引（二级索引）

| 分类     | 含义                                                     | 特点                 |
| :------- | :------------------------------------------------------- | -------------------- |
| 聚焦索引 | 将数据存储与索引放到了一块，B+树叶子结点保存了**行数据** | 必须有，而且只有一个 |
| 二级索引 | 将数据与索引分开存储，B+树叶子结点保存的是对应的**主键** | 可以存在多个         |

**聚集索引选取规则**：

1. 如果存在主键，主键索引就是聚焦索引
2. 如果不存在主键，将使用第一个唯一（UNIQUE）索引作为聚焦索引
3. 如果表没有主键或合适的唯一索引，则InnoDB会自动生成一个rowid作为隐藏的聚焦索引

![image-20240804200928767](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408042009902.png)

##### 回表查询

回表查询：通过二级索引查询到主键，根据主键到聚焦索引中查询整行数据

```sql
select * from user where name = 'Arm';
```

通过二级索引查询 `Arm` 找到主键为`10`，根据 `10`到聚焦索引中查询到该行数据

##### 覆盖索引

覆盖索引：是指查询使用了索引，并且需要返回的列，在该索引中已经全部能够找到

- 使用id查询，直接走聚焦索引查询，一次索引扫描，直接返回数据，性能高
- 如果返回的列中没有创建索引，有可能会触发回表查询，影响查询效率，尽量避免使用select*

![image-20240804205133523](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408042051682.png)

##### Mysql超大分页处理

在数据量比较大时，如果进行limit分页查询，在查询时，越往后，分页查询效率较低

```sql
select * from tb_sku limit 9000000,10;
```

大偏移量下查询到的前9000000行数据都需要丢弃，代价很大

**优化思路**：一般分页查询时，通过创建 ==覆盖索引==能够比较好的提高性能，可以通过 ==覆盖索引+子查询==的形式优化

```sql
select * 
from tb_sku t,
(select id from tb_sku order by id limit 9000000,10) a
where t.id = a.id;
```

==优化==：索引覆盖+子查询

> 先查询第1000001条数据的id，根据id来查询往后的数据

```mysql
select a.empno,
		 a.ename,
		 b.deptno
from emp e
	left join dept b
		on a.deptno = b.deptno
where a.id >= (select id from emp order by id limit 1000000,1)
order by a.id 
limit 50;
```

#### 索引创建原则

![image-20240804210832091](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408042108212.png)

#### 索引失效

给`tb_seller`创建联合索引，字段顺序：`name`、`status`、`address`

```sql
create index tb_seller_index on tb_seller (name,status,address);
```

##### 1.最左前缀法则

如果索引了多列，要遵守最左前缀法则。指的是查询从索引的最左前列开始，并且不跳过索引中的列，匹配最左前缀法则，走索引：

```sql
# 正常情况 key = tb_seller_index key_len = 303
explain select * from tb_seller where name = '小米科技';
# key_len = 309
explain select * from tb_seller where name = '小米科技' and status = '1';
# key_len = 612
explain select * from tb_seller where name = '小米科技' and status = '1' and address = '北京市';

# 违反失效情况 key = NULL
explain select * from tb_seller where status = '1';
explain select * from tb_seller where status = '1' and address = '北京市';

# 符合最左法则，跳跃了某一列，只有最左索引失效 key = tb_seller_index  key_len = 303
explain select * from tb_seller where name = '小米科技' and address = '北京市';
```

##### 2.范围查询

范围查询右边的列，不能使用索引

```sql
# key = tb_seller_index  key_len = 309
explain select * from tb_seller where name = '小米科技' and status > '1' and address = '北京市';
```

根据前面的两个字段 `name`，`status`查询时走索引的，但是最后一个条件`address`没有用到索引

##### 3.索引上运算操作

```sql
# key = null
explain select * from tb_seller where substring(name,3,2) = '科技';
```

##### 4.字符串不加单引号

(类型转换)

```sql
# key = tb_seller_index  key_len = 309
explain select * from tb_seller where name = '科技' and status = '0';
# key = tb_seller_index  key_len = 303
explain select * from tb_seller where name = '科技' and status = 0;
```

##### 5.模糊查询

以 `%` 开头的Like模糊查询，索引失效。如果仅仅是尾部模糊匹配，索引不会失效。如果头部模糊匹配，索引失效。

```sql
# key = null
explain select sellerid,name from tb_seller where name like '%程序员';
# key = tb_seller_index  key_len = 303
explain select sellerid,name from tb_seller where name like '程序员%';
```

#### SQL优化经验

- 表的设计优化
- 索引优化
- SQL语句优化
- 主从复制，读写分离
- 分库分表

##### 表的设计优化

1. 设置合适的数值（tinyint int bigint），要根据实际情况选择
2. 设置合适的字符串类型（char varchar）char定长效率高，varchar可变长度，效率稍低

##### SQL语句优化

1. SELECT 语句务必指明字段名称（避免直接使用select *）

2. SQL语句要避免造成索引失效的写法

3. 尽量用`union all` 代替 `union`，union会多一次过滤去重，效率低

   ```sql
   select * from t_user where id > 2
   union all | union
   select * from t_user where id < 5
   ```

4. 避免在where子句中对字段进行表达式操作

5. `Join`优化 能用`innerjoin` 就不用`left join`、`right join`，如必须使用，一定要以小表为驱动，内连接会对两个表进行优化，优先把小表放到外边，把大表放到里边。left join、right join不会重新调整顺序

##### 主从复制、读写分离

如果数据库的使用场景读的操作比较多的时候，为了避免写的操作所造成的性能影响，可以采用读写分离的架构。

读写分离解决的是，数据库的写入，影响了查询的效率

![image-20240804214857832](https://gitee.com/yurun-zhang/typora-tu-chuang/raw/master/202408042148965.png)
